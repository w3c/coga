<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <title>Supplementing text with multi-modal content</title>
</head>
<body>
    <section>
        <h1>Supplementing text with multi-modal content</h1>
<p>This document is an issue paper about the challenges and issues faced by users with cognitive disabilities when consuming web content. This is part of a series of issue papers written by the <a href="https://www.w3.org/WAI/PF/cognitive-a11y-tf/">Cognitive and Learning Disabilities Accessibility Task Force (COGA)</a>. It is a joint Task Force of the <a href="http://www.w3.org/WAI/APA/">Accessible Platform Architectures (APA) Working Group</a> and the <a href="http://www.w3.org/WAI/GL/">Web Content Accessibility Guidelines Working Group (WCAG WG)</a>. This work will be used as a base document for other work, including a road-map for improving accessibility for people with cognitive disabilities.</p>        
        <h2> Description of the Multi-Modal Content </h2>
        <p>Textual content can be made easier to understand when delivered in different modes to help people with cognitive disabilities. These modes can include the addition of:</p>
        <ul>
            <li>speech, via text-to-speech (TTS);</li>
            <li>video;</li>
            <li>contextually-relevant images;</li>
            <li>consistent icons and graphics; and / or</li>
            <li>text replaced or augmented by symbol sets.</li>
        </ul>
    </section>
    <section>
        <h2> Challenges of text for people with cognitive disabilities </h2>
        <p>Difficulty of text comprehension by people with cognitive disabilities ranges from minimal to extreme. They may comprehend most of a web page's textual content, or none at all. These can impact people with impairments of:</p>
			<ul>
				<li>memory; </li>
				<li>executive function;</li>
				<li>attention;</li>
				<li>language;</li>
				<li>literacy;</li>
				<li>perception processing;</li>
				<li>knowledge.</li>
			</ul>
        <section>
            <h3>Memory </h3>
            <p>People with cognitive disabilities may have to:</p>
            <ul>
                <li>read text several times to aid comprehension;</li>
                <li>repeat aloud or otherwise reiterate text multiple times to retain it; and/or</li>
                <li>return to sections when difficulties mean they cannot retain information because content has taken too long to read.</li>
            </ul>
            <p>Issues with working memory may affect ability to multi-task so multi-modal approach needs to be used judiciously with user choice depending on the tasks in hand and the setting. See  [[Price-2]] and [[Sanderson-1]].</p>
            <p>“Good cues for individuals without EMI (episodic memory impairment) can be more subtle and less central to the experience, whereas good cues for those with memory impairment  need to cover the important highlights of the experience so that they can re-learn and re-construct the forgotten experience […] Individuals with EMI are more easily cognitively overloaded, which leads to a need for systems to present a smaller number of only the most powerful cues.” See [[Lee-1]]</p>   
        </section>
        <section>
            <h3>Executive function </h3>
            <p>People with cognitive disabilities may not:</p>
            <ul>
                <li>sufficiently process / understand text as they read it; </li>
                <li>understand text because they did not understand the text that preceded it; and/or</li>
                <li>be able to plan which text to read next despite clues such as headings or numbering.</li>
            </ul>
        </section>
        <section>
            <h3>Attention-related limitations </h3>
            <p>People with cognitive disabilities:</p>
            <ul>
                <li>may not attend to important concepts and relevant details; and/or</li>
                <li>may be significantly distracted by extraneous text.</li>
            </ul>
        </section>
        <section>
            <h3>Language-related functions </h3>
            <p>People with cognitive disabilities may not understand text because they:</p>
            <ul>
                <li>are unable to sound out letters or words;</li>
                <li>are confused by text written in their language, but  written with vocabulary from a different culture;</li>
                <li>are stymied by too-complex text written in their native language; and/or</li>
                <li>may have comprehension problems exacerbated by text or instructions presented in a non-native language.</li>
            </ul>
        </section>
        <section>
            <h3>Literacy-related functions </h3>
            <p>Some people with cognitive disabilities may not:</p>
            <ul>
                <li>cope with sounds or syllables that comprise words;</li>
                <li>understand text because it is not literal and written plainly; and/or</li>
                <li>comprehend text-only instructions in order to adequately follow them.</li>

            </ul>
        </section>
        <section>
            <h3>Perception-processing limitations </h3>
            <p>Many people with cognitive disabilities may not:</p>
            <ul>
                <li>comprehend text that can't be enlarged without distortion;</li>
                <li>recognize characters if they do not form words, or are shown in different fonts or styles, e.g., italics.</li>
            </ul>
        </section>
        <section>
            <h3>Reduced knowledge </h3>
            <p>Some people with cognitive disabilities may not comprehend text because:</p>
            <ul>
                <li>they do not have relevant background knowledge; and/or</li>
                <li>background concepts are not explained simply.</li>
            </ul>
        </section>
    </section>
		<section>
			<h2>Use cases for multi-modal content</h2>
			<p>Other use cases include:</p>
			<ol>
				<li>Jumping to the relevant part of content. This is typically not supported, making content less usable.</li>
				<li>Finding pieces in the content once focus is lost.</li>
				<li>Going back a step when something was not understood.</li>
				<li>Going back and forth between where a term was explained and the content of focus.</li>
			</ol>
		</section>
    <section>
        <h2> Ways to enhance text with multi-modal content</h2>
        <p>Text is written communication.</p>
        <p>Textual content can be provided in a variety of alternative modes / formats as described below. Ideally, people with cognitive disabilities should be able to choose that content is delivered in the mode they comprehend best. This is an important component of the proposed <a href="http://gpii.net/">Global Public Inclusive Infrastructure</a>.</p>
        <h3>Text-to-speech</h3>
        <p>Text-to-speech (TTS) is hardware and/or software that produces human speech by a device such as a computer. Most <abbr title="Text To Speech">TTS</abbr> reads text aloud in a synthesized voice. Other <abbr title="Text To Speech">TTS</abbr> converts symbols, such as those employed by augmentative and alternative communication (AAC), into spoken speech.</p>
        <p>Many people with cognitive disabilities, such as Dyslexia, may have the capacity to use a screen reader for TTS. However, people with severe cognitive disabilities, such as intellectual disabilities, may require simpler <abbr title="Text To Speech">TTS</abbr> delivery.</p>
        <p>A common example is a <abbr title="Text To Speech">TTS</abbr> widget embedded in a website. An alternative is a <a href="http://www.w3.org/TR/css3-speech/"> <abbr title="Cascading Style Sheets">CSS</abbr> speech module, as proposed by the <abbr title="World Wide Web Consortium">W3C</abbr></a>. Advantages include that there is nothing to download and install; and learning how to use a <abbr title="Text To Speech">TTS</abbr> widget or a <abbr title="Cascading Style Sheets">CSS</abbr> speech module is dramatically simpler than learning how to use a screen reader.</p>
        <p>The <abbr title="Text To Speech">TTS</abbr> should be limited to relevant content, and exclude such text as found in menus, footers, and advertisements. Another helpful feature is the visual highlighting of text as it is read aloud. Such features may help people with cognitive disabilities who are overwhelmed even by simple <abbr title="Text To Speech">TTS</abbr> delivery.</p>
        <p>There is an overwhelming amount of research that shows a multi-modal approach can “enhance assimilation of information” when text and numerical information are read aloud (See [[Shany-1]], [[Hecker-1]], [[Gy-1]], [[Lacina-1]].); video options are provided ([[Lacina-1]], [[Deibel-1]].); and there are multiple means of navigation and interaction (See [[Doyle-1]].) with clear layout, headings, and use of imagery (See [[Lacina-1]].).</p>
        <h3> Video </h3>
        <p>Video is a short film clip of moving visual images with or without audio.</p>
        <p>To aid comprehension, video with audio should be captioned and/or have audio description, which provides important information not described or spoken in the main sound track. For example, see <a href="http://mindfulresearch.co.uk/2011/08/29/autistic-spectrum-captions-and-audio-description/">"Autistic spectrum, captions and audio description".</a></p>
        <p>Further, video and audio should be navigable, such as:</p>
        <ol>
            <li>Having the content structured such that it is clearly identified or signposted (e.g., with a slide that says "step two - remove the old washer" or "step three - put on the new washer")</li>
            <li>The structure is navigable (e.g., a person can jump directly to step two)</li>
            <li>Keywords are identified, and can be jumped to directly</li>
            <li>Enabling bookmarks and annotations (that can be navigated)</li>
        </ol>
        <p>WCAG 2.0 Success Criterion References:</p>
        <ul>
            <li><a href="http://www.w3.org/TR/UNDERSTANDING-WCAG20/media-equiv-captions.html">1.2.2 Captions (pre-recorded):</a> Captions are provided for all pre-recorded audio content in synchronized media, except when the media is a media alternative for text and is clearly labeled as such. (Level A)</li>
            <li><a href="http://www.w3.org/TR/UNDERSTANDING-WCAG20/media-equiv-audio-desc-only.html">1.2.5 Audio Description (pre-recorded):</a> Audio description is provided for all pre-recorded video content in synchronized media. (Level AA)</li>
            <li><a href="http://www.w3.org/TR/UNDERSTANDING-WCAG20/media-equiv-extended-ad.html">1.2.7 Extended Audio Description (pre-recorded):</a> Where pauses in foreground audio are insufficient to allow audio descriptions to convey the sense of the video, extended audio description is provided for all pre-recorded video content in synchronized media. (Level AAA)</li>
        </ul>
        <h3>Supplement with contextually-relevant images </h3>
        <p>An image is a picture, a representation of a visual perception.</p>
        <p>User research has shown that text comprehension is significantly enhanced where accompanied by contextually-relevant images. A picture of an object may be easier to recognize than a textual description of it.</p>
        <p>Diagrams and charts as visual representations could be helpful for textual descriptions of processes or flows. Employing <a href="http://www.w3.org/TR/2dcontext/">HTML Canvas, as proposed by the <abbr title="World Wide Web Consortium">W3C</abbr></a>, diagrams and charts could be interactive and have additional descriptions for their parts to aid comprehension.</p>
        <h3>Supplement with consistent icons and graphics </h3>
        <p>An icon is a small image or drawing that commonly represents a function. A graphic is a drawing of a visual perception or an abstract concept, or is otherwise a representation of an object or an idea.</p>
        <p>Text accompanied by consistent iconography helps convey meaning, such as by associating discrete textual passages with each other. Similarly, a pie-chart graphic may help convey meaning easier to comprehend than a table of statistics.</p>
			<p class="ednote">What is "consistent" in this context?</p>
        <h3>Replace or augment by symbol sets </h3>
        <p>A symbol is a sign that represents or suggests an idea, an object, an action, or a belief.</p>
        <p>Symbol sets can be used for augmentative and alternative communication (AAC) to support people with cognitive disabilities who have severe speech and/or language difficulties. This can include those who may understand speech, but who are unable to express what they wish to say, perhaps because of a physical disability. (It is common for people with cognitive disabilities to also have physical disabilities.) Ideally, <a href="https://w3c.github.io/coga/issue-papers/symbols-non-verbal.html">interoperable symbol sets could be used to replace or to augment web-based text</a>.</p>
    </section>
    <section>
        <h3>Ease-of-use ideas</h3>
        <p>Text should be written clearly and simply using the following attributes:</p>
        <ul>
            <li>
                plain-language standards relevant to language and culture;
                <ul>
                    <li>(Examples for English include:</li>
                    <li>literal explanations, e.g., without jargon, slang, and metaphors;</li>
                    <li>active voice, not passive voice; and</li>
                    <li>no or minimal use of acronyms and abbreviations.)</li>
                </ul>
            </li>
            <li>visual and organizational structures, e.g., headings and bulleted lists;</li>
            <li>large font size; and</li>
            <li>sans-serif font</li>
        </ul>
        <p>Plain language and clear structure will help comprehension of text-to-speech users.</p>
    </section>
</body>
</html>
