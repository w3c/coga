<!DOCTYPE html><html lang="en" xmlns="http://www.w3.org/1999/xhtml">
	<head><meta charset="utf-8"/>
		<title>Cognitive Accessibility Research Modules - Voice Systems and Conversational Interfaces
</title>
		
		
	<meta name="description" content="Issues for users with cognitive disabilities using conversational voice systems, including voice menu systems."/>
			<script src="https://www.w3.org/Tools/respec/respec-w3c" class="remove"></script>
		<script src="biblio.js" class="remove"></script>
		<script class="remove">
	var respecConfig = {
		// embed RDFa data in the output
		specStatus: "ED",
            noRecTrack: true,
            //crEnd:                "2012-04-30",
            //perEnd:               "2013-07-23",
            publishDate:          "2026-01-22",
            //diffTool:             "http://www.aptest.com/standards/htmldiff/htmldiff.pl",

            // the specifications short name, as in http://www.w3.org/TR/short-name/
            shortName: "coga-voice",


            // if you wish the publication date to be other than today, set this
            //publishDate:  "2017-05-16",
            copyrightStart: "2026",
            license: "document",

            // if there is a previously published draft, uncomment this and set its YYYY-MM-DD date
            // and its maturity status
            //previousPublishDate:  "",
            //previousMaturity:  "",
            //prevRecURI: "",
            //previousDiffURI: "",

            // if there a publicly available Editors Draft, this is the link
            edDraftURI: "https://w3c.github.io/coga/research-modules/Conversational-Voice-Systems.html",

            // if this is a LCWD, uncomment and set the end of its review period
            // lcEnd: "2012-02-21",

            // editors, add as many as you like
            // only "name" is required
            editors: [
                  {
                        name: "Lisa Seeman-Horwitz",

                        mailto: "lisa.seeman@zoho.com"
                  },

            ],

            // authors, add as many as you like. 
            // This is optional, uncomment if you have authors as well as editors.
            // only "name" is required. Same format as editors.

            //authors:  [
            //    { name: "Your Name", url: "http://example.org/",
            //      company: "Your Company", companyURI: "http://example.com/" },
            //],

            /*
            alternateFormats: [
                  { uri: 'aria-diff.html', label: "Diff from Previous Recommendation" } ,
                  { uri: 'aria.ps', label: "PostScript version" }, 
                  { uri: 'aria.pdf', label: "PDF version" }
            ],
            */

            // errata: 'http://www.w3.org/2010/02/rdfa/errata.html',

            // name of the WG
            group: ["apa", "ag"],

            // name (with the @w3c.org) of the public mailing to which comments are due
            wgPublicList: "public-coga-comments",

            // URI of the patent status for this WG, for Rec-track documents
            // !!!! IMPORTANT !!!!
            // This is important for Rec-track documents, do not copy a patent URI from a random
            // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
            // Team Contact.

            //maxTocLevel: 2,

            localBiblio: biblio,
            github: "w3c/coga",
	};
		</script>

	</head>
		
 <body>
	 
	 
 <section id="abstract">
<p>Voice systems and conversational interfaces can create a number of cognitive accessibility issues for people with disabilities. These technologies include artificial intelligence (AI) voice assistants, natural language processing (NLP) systems, voice menu systems, and interactive voice response (IVR) systems.
</p>
<p>This module explores:</p>
<ul>
    <li>
        cognitive accessibility issues that may arise when using voice systems and conversational interfaces,
    </li>
    <li>
        key user needs and ways to address these barriers, and
    </li>
    <li>
        areas for further research.
    </li>
</ul>

	<p>Research modules are <strong>primarily intended for groups in The World Wide Web Consortium (W3C).</strong> For example, they are used as source material for <a  href="https://www.w3.org/TR/coga-usable/">Making Content Usable for People with Cognitive and Learning Disabilities</a>.</p>
<p>They may also contain useful information for:</p>
<ul>
    <li>
        researchers,
    </li>
    <li>
        inclusion and research-related policy makers,
    </li>
    <li>
        designers, content creators, and developers who wish to have a more in-depth understanding of inclusion issues.
    </li>
</ul>
<p>Note that these modules focus on explaining the issues that lead to diverse user needs impacting web accessibility. For this reason, they may sometimes address a broader scope than web accessibility alone.</p>

<p>This document is part of a set of modules that describe accessibility issues for users with various disabilities that impact cognitive accessibility. See <a href="https://raw.githack.com/w3c/coga/issue-papers-v2/issue-papers/index.html">cognitive or learning disabilities research modules</a> for other modules.</p>
<p>This document is part of a set of related informative publications from the <a href="http://www.w3.org/WAI/PF/cognitive-a11y-tf/">Cognitive and Learning Disabilities Accessibility Task Force</a> (COGA TF), a joint task force of:</p>
<ul>
    <li>
        <p>the <a  href="http://www.w3.org/WAI/APA/">Accessible Platform Architectures Working Group</a> (APA WG), and</p>
    </li>
    <li>
        <p>the <a  href="http://www.w3.org/WAI/GL/">Accessibility Guidelines Working Group</a> (AG WG) of the <a href="http://www.w3.org/WAI/">Web Accessibility Initiative</a>.</p>
    </li>
</ul>

		</section>
		<section id="sotd">
			<p class="ednote"  Title = "Early Draft">This is an early draft. The task force intends to add more research and discussion and make editorial changes to comply with our style guide, including for citations. Please share your feedback, including any research we should consider adding to this document.</p>
<p>This document is part of a set of modules or papers that describe accessibility issues for users with various disabilities that impact cognitive accessibility. See <a   href="https://raw.githack.com/w3c/coga/issue-papers-v2/issue-papers/index.html"> cognitive or learning disabilities research modules </a> for other modules.</p>
<p>This document is part of a set of related informative publications from the <a   href="http://www.w3.org/WAI/PF/cognitive-a11y-tf/"> Cognitive and Learning Disabilities Accessibility Task Force </a> (COGA TF), a joint task force of:</p>
<ul>
    <li>
        the <a   href="http://www.w3.org/WAI/APA/"> Accessible Platform Architectures Working Group </a> (APA WG), and
    </li>
    <li>
        the <a   href="http://www.w3.org/WAI/GL/"> Accessibility Guidelines Working Group </a> (AG WG) of the <a   href="http://www.w3.org/WAI/"> Web Accessibility Initiative </a>.
    </li>
</ul>
<p>Feedback on any aspect of the document is welcome. The APA and AG Working Groups particularly seek feedback on the following questions:</p>
<ul>
    <li>
       Are issues for the included user groups well covered?
    </li>
    <li>
        Does the research module effectively bridge between research and priorities for new work?
    </li>
    <li>
       Should additional user groups be addressed?
    </li>
    <li>
        Are there any more research papers we should consider adding to this document?
    </li>
</ul>
<p>To comment, <a   href="https://github.com/w3c/coga/issues/new"> file an issue in the W3C coga GitHub repository </a>. You can also send an email to <a   href="mailto:public-coga-comments@w3.org">public-coga-comments@w3.org</a> (<a   href="http://lists.w3.org/Archives/Public/public-aria/"> comment archive </a>). Comments are requested by 15th April 2026. In-progress updates to the document may be viewed in the <a   href="http://w3c.github.io/coga/issue-papers/"> publicly visible editors' draft </a>.</p>
		</section>
 
		 <section><h2>Introduction </h2>
			<p>This module looks at cognitive accessibility issues that may arise when using voice systems and conversational interfaces. These technologies involve bi-directional communication:</p>
<ul>
    <li>
        <p>The user speaks and the system talks back, or</p>
    </li>
    <li>
        <p>The system speaks and the user answers by talking or pressing a button.</p>
    </li>
</ul>
<h4> Disabilities that may require cognitive accessibility support </h4>
<p> Disabilities that may require cognitive accessibility support include:</p>
<ul>
    <li>
       cognitive, developmental, intellectual, learning, and specific learning disabilities,
    </li>
    <li>
       language and communication disorders,
    </li>
    <li>
        neurodivergence,
    </li>
    <li>
        traumatic brain injury,
    </li>
    <li>
        age-related cognitive decline,
    </li>
    <li>
       mental health disabilities, and
    </li>
    <li>
        temporary impairments that affect cognitive function, such as anxiety, illness, effects of medication, treatments such as chemotherapy, and others.
    </li>
</ul>
<p>Examples of specific disabilities that may require cognitive accessibility support include attention deficit hyperactivity disorder (ADHD),  autism spectrum disorder, dyslexia, dyscalculia, mild cognitive impairment (MCI), Down syndrome, aphasia, and others. 
</p>
<p>Cognitive accessibility also supports benefit a broad range of users, including:</p>
<ul>
    <li>
        people who may not be fluent in a language, and
    </li>
    <li>
      people who may have different educational or cultural backgrounds.
    </li>
</ul>
			 
<h4> Voice systems and conversational interfaces </h4>
<p>Voice systems and conversational interfaces may include:</p>
<ul>
    <li>
        <strong>Voice Menu Systems</strong> in telephone self-service applications that require the user to respond by pressing keys or saying words. These systems are sometimes called  interactive voice response (IVR). 
            </li>
</ul>
<ul>
    <li>
        <strong>Voice User Interfaces (VUIs)</strong> or conversational interfaces such as Amazon Alexa, Cortana, Google Assistant, or Siri. These interfaces tend to use voice recognition, natural language processing (NLP), and artificial intelligence (AI) to understand and respond to users.
    </li>
</ul>
<p>It is worth noting that many crucial systems integrate voice systems and conversational interfaces, including emergency notifications, healthcare scheduling, prescription refilling, and more. With this in mind, full accessibility needs to be supported.</p>
<p>An example use case of a voice system used in telephone self-service may be as follows:</p>
<ul>
    <li>
      Upon dialing the number, the user may be asked: "Press 1 for hours of operation, press 2 to refill your prescription, press 3 to speak to the pharmacist.” The system then waits for a response.    </li>
</ul>
<p>An example use case for a conversational interface may be as follows:</p>
<ul>
    <li>
        The user says the activating phrase to begin an interaction with the VUI such as “Hello, [Name of System].” The user then asks, “What is the weather forecast for today?” The VUI provides a verbal response.
    </li>
</ul>
<p>Voice systems are often implemented with the <a   href="https://www.w3.org/TR/voicexml20/"> W3C VoiceXML 2.0 </a> [[voicexml20]] standard and supporting standards from the <a   href="https://www.w3.org/Voice/"> Voice Browser Working Group </a>. [[VBWG]]</p>
<p>VoiceXML 2.0 has an appendix regarding accessibility that briefly discusses users with hearing and speech disabilities as well as WCAG and WAI specifications. Cognitive disabilities are mentioned once in a bullet about allowing users to control the length of time before a timeout. See <a   href="https://www.w3.org/TR/voicexml20/#dmlAAccessibility"> VoiceXML 2.0 </a> [[voicexml20]] Appendix H - Accessibility.</p>
<p class="ednote">We are planning to expand this paper to include more information about challenges with internationalization and localization that users may encounter with voice systems and conversational interfaces.</p>
 <p>This module focuses on explaining the issues that lead to diverse user needs impacting web accessibility. For this reason, it may sometimes
address a broader scope than web accessibility alone.</p> 
</section>
 <section>
<h2>Challenges for People with Disabilities that Impact Cognitive Accessibility</h2>
<p>Voice systems and conversational interfaces can create a number of cognitive accessibility barriers.<em> </em>These technologies can create challenges due to heavy demands on memory and on the ability to understand and produce speech in real time. In particular, voice systems and VUIs can be inaccessible to people with disabilities that affect:</p>
<ul>
    <li>
          memory,</p>
    </li>
    <li>
          executive function (the brain’s ability to plan, focus, remember, and manage tasks and emotions),  
    </li>
    <li>
          reasoning,  
    </li>
    <li>
          knowledge,  
    </li>
    <li>
          processing speed.  
    </li>
    <li>
          attention,  
    </li>
    <li>
          language and auditory perception,  
    </li>
    <li>
          speech and language production and comprehension, and  
    </li>
    <li>
          mental health.  
    </li>
</ul>
<h3> General Concerns </h3>
<p>Voice systems and conversational interfaces depend on the users’ knowledge and abilities. Many groups fall outside the norm in these categories. In these cases, the system often fails.</p>
<p><strong>Training and artificial intelligence (AI):</strong> User groups in this module's scope often have different speech patterns, vocabulary, impaired memory, executive function, and cognitive function.</p>
<p>For the system to work well, it must be trained with a set of training content where different abilities and impairments are well represented. This includes long-term impairments such as mild cognitive impairment (MCI), learning disabilities, intellectual disabilities, and mood disorders, as well as temporary disabilities such as stress.</p>
<p><strong>Requirements, user needs, and functional needs: </strong>Similarly, when teams use user needs and functional needs in the product lifecycle, they often focus on peers or groups with biases in terms of cognitive abilities. For example, university students are often used for focus groups, but often do not represent cognitive and speech issues associated with aging. It is essential to include user needs from a diverse perspective beyond neurotypical audiences (See <a   href="https://docs.google.com/document/d/1B1vCqlU1IF5UmqxhJAy8Khdi-kRQNPalVX8f3lCMr7w/edit?tab=t.0#heading=h.at0k2knwycsb"> User Story and User Needs </a>.)</p>
<p><strong>Testing:</strong> It is also essential to test with a wide group of users with diverse cognitive abilities to determine whether the system actually works as intended. Watch for increased levels of frustration, errors, and worsening of the users’ mood.</p>

<h3> Memory: Recalling and Responding to Prompts </h3>
<p><strong>General: </strong>The user needs to recall information to successfully interact with the system, such as activating phrases, as well as information presented by the system during the interaction.</p>
<p><strong>Voice Menu Systems: </strong>Menus that present several choices at once may pose challenges for users with disabilities related to working memory. Such systems require users to hold multiple pieces of information, such as the number associated with an option, while processing the terms that follow. This is true of systems that require either a voice response or a key press.</p>
<p>Many designers assume that users can remember lists of about seven items. This assumes a typical working memory. People with impaired working memory can hold significantly fewer items simultaneously. As a result, they may not be able to use a system that requires them to compare items or remember numbers while processing words or directions.</p>
<p>However, with a supportive design and prompts that reduce cognitive load, voice menus can be used even by people who can only hold two or three items in their working memories.</p>
<p>For example, the instruction “to speak to a nurse, press 2” stands by itself and does not require remembering anything before or after. Pausing between “to speak to a nurse” and “press 2” gives users time to decide if they want to speak to a nurse before they are given the rest of the instructions. The order of the instruction is important, and so is the pacing. The goal is to give users time to process the prompt and reduce the need for memory.</p>
<p><strong>Voice User Interfaces: </strong>For VUIs, users may be required to remember key phrases (such as activating phrases like “Hey, Google”) in order to operate successfully. Users who have difficulty recalling such phrases due to long-term memory impairments may not be able to operate the system.</p>

<h3> Executive Function: Deciding When to Respond </h3>
<p><strong>General: </strong>If a system response is too slow, a user with disabilities related to executive functioning may not know if their input was received and may press the key or speak again.</p>
<p><strong>Voice Menu Systems: </strong>The user needs to be able to decide when to act on a menu choice. If the user does not know how many options will be presented or if the system presents them too slowly, the user may make an incorrect choice based on partial information.</p>

<h3> Reasoning: Making the Correct Selection </h3>
<p><strong>Voice Menu Systems: </strong>The user may need to compare similar options such as "billing," "accounts," and "sales," and decide which one is best suited to accomplish their goal. Without additional context or prior knowledge, the user is likely to select the wrong menu option.</p>

	 <h3> Knowledge: Interpreting Responses </h3>
<p><strong>General: </strong>If responses produced by a system are not provided in clear and accessible language, the user may have difficulty interpreting them. The user may not understand the response or know if they are using the system correctly.</p>
<h3> Processing Speed </h3>
<p><strong>General: </strong>Systems that time out may not give users with disabilities that affect processing speed sufficient time to interpret information and formulate a response. Advertisements and additional, unrequested information also increase the amount of processing required.</p>
<h3> Attention: Making Correct Selections </h3>
<p><strong>Voice Menu Systems: </strong>The user needs to focus on the different options and select the correct one. It can be challenging to focus on long or multi-level spoken menus without written counterparts. Advertisements or other unrequested information may also make it harder for users with attention-related disabilities to stay focused on the task they are trying to complete.</p>
<h3> Language and Auditory Perception: Correctly Interpreting Spoken Information </h3>
<p><strong>General: </strong>The user needs to interpret the terms and choose the one that most closely matches the user’s goal. This involves speech perception, language understanding, and time limits. The sounds of language need to be heard, interpreted, and understood within a given time.</p>
<p>Users with disabilities related to language and auditory perception may make mistakes in interpretation due to auditory-only input.</p>
<h3> Speech and Language Production: Responding to Voice and Speech Recognition Systems </h3>
<p>We identified three issues to consider that apply to all kinds of voice systems or conversational interfaces:</p>
<p><strong>Timeouts: </strong>The user needs to formulate a spoken response to the prompt before the system "times out" and generates another prompt. For example: Users of assistive and augmentative communication devices (AAC) or speech-to-speech technologies may require significant additional time to respond before the system times out.</p>
<p><strong>Spontaneous speech:</strong> In directed dialog systems that<span style="color: rgb(71, 71, 71)">  guide the user through a series of predefined questions and responses, the user only needs to be able to speak a word or short phrase. However, the increasing use of natural language systems means the user may need to describe their issue in their own words. This feature is an advantage for some users because it does not require them to remember menu options. But it can be problematic for users with disabilities that impact their ability to produce spontaneous speech, such as people with aphasia or autistic people for whom stress may impact spoken communication.</p>
<p><strong>Speech recognition:</strong> Speech recognition systems might not work well for people whose speech sounds different. Users may not be able to interact with a system that requires verbal input but does not recognize their speech. This affects many groups such as users with MCI or Down syndrome.</p>

	 <h3> Mental Health: Interacting with Voice Systems and Conversational Interfaces </h3>
<p><strong>General: </strong>Mental health, such as anxiety, may also impact a user’s ability to interact with voice systems or conversational interfaces. High demands on cognitive load, negative experiences with technology, and interruptions can exacerbate anxiety or frustration, and decrease a user’s ability to interact with a system. Note that many people requiring cognitive accessibility supports find their skills are reduced as anxiety and cognitive load increases.</p>
</section><section>	
	<h2>User Story and User Needs</h2>
<p class="ednote">This list of user needs is not complete. We are also seeking feedback on the format for presenting user needs.</p>
	 <p class="ednote">In the next version, we will cross-reference this section with the user needs in <a  href="https://www.w3.org/TR/coga-usable/">Making Content Usable for People with Cognitive and Learning Disabilities</a>. New user needs that are identified in this research module will be included in the next version of <a  href="https://www.w3.org/TR/coga-usable/">Making Content Usable for People with Cognitive and Learning Disabilities</a>. </p>
<p>As a user who has cognitive accessibility needs, I need to get human help, without going through a complex menu system (VoiceXML [[voicexml30]]) or a complex voice recognition menu system that relies on memory and <a   href="https://raw.githack.com/w3c/coga/MH_Proposals/content-usable/index.html#dfn-executive-function"> executive function </a>, so that I can set an appointment or find out some information.</p>
<p>As a user who has cognitive accessibility needs, I need to use the system without relying on a good memory, learning new information, or dealing with distraction or cognitive overload.</p>
<h3> Related user needs </h3>
<ol>
    <li>
          I need to complete my task without learning new terms or phrases.  
    </li>
    <li>
          I need to complete my task without remembering option values such as “press 2” for something.  
    </li>
    <li>
          When I need to choose an option, I need clear understandable information so I can hear the option before the number to select, so I do not have to remember the number while processing the words.  
    </li>
    <li>
          When I need to choose an option, I need the choices presented in a way that does not expect me to remember multiple options, criteria, or prompts at the same time.  
    </li>
    <li>
          I need all the information to make the right choice before I forget options.  
    </li>
    <li>
          I need to easily find a process to select simple help, and not multi-step help.  
    </li>
    <li>
          I need to easily find a human by pressing a reserved digit that I know (typically the number 0).  
    </li>
    <li>
          I need simple-to-navigate voice-menu systems with limited options that make sense to me, so I can identify options quickly and don’t struggle with multiple steps.  
    </li>
    <li>
          I need to know if my response was okay so I know what is going on and don’t get too frustrated.  
    </li>
    <li>
          As a user with impaired processing speed, I need sufficient time and pauses between each option so I can process what was said.  
    </li>
    <li>
          I need time to look up any information requested such as my phone number, as I do not always remember it.  
    </li>
    <li>
          I need to know where I am in the process and if the step is completed.  
    </li>
    <li>
          I need the system to recognize my speech even if it is not typical.  
    </li>
    <li>
          As a slow speaker, I need the system to wait for my response.  
    </li>
    <li>
          I need to easily go back when I make a mistake, without having to start at the beginning.  
    </li>
    <li>
          As a user who often finds menus unusable, I need usability best practices to help me navigate voice systems.  
    </li>
    <li>
          I need to spend my energy completing my task. I do not want to waste my energy while I struggle to understand other material, such as special offers or promotions.  
    </li>
    <li>
          I need to focus on my task to remember what I am doing. Please do not give me distracting information such as special offers, in the middle of my task.  
    </li>
    <li>
          I need the steps to be as short as possible so I do not get cognitive overload.  
    </li>
    <li>
          I need help identifying the right words to say in a voice menu, and the words should be the ones I would use.  
    </li>
    <li>
          I need a process that I can use that does not rely on a lot of words.  
    </li>
    <li>
          I need processes that do not rely on memory or access to information that I entered during previous steps in a process.  
    </li>
    <li>
          I need to be able to use a site without remembering or transcribing passwords, codes, and usernames.  
    </li>
    <li>
          I need to know what the next steps are and when I am finished.  
    </li>
</ol>
<h3> <strong>Related Personas</strong> </h3>
<ul>
    <li>
          <a   href="https://raw.githack.com/w3c/coga/MH_Proposals/content-usable/index.html#gopal-a-retired-lawyer-with-dementia"> Gopal </a>
          
    </li>
    <li>
          <a   href="https://raw.githack.com/w3c/coga/MH_Proposals/content-usable/index.html#maria-a-user-who-has-memory-loss"> Maria </a>
          
    </li>
</ul>
 </section><section>	
<h2>Possible Solutions for Meeting User Needs</h2>
			<p>Below are some ideas that might help meet the user needs above. Note that
digital solutions should also meet [[WCAG21]] and [[coga-usable]]. Also, this module focuses on explaining the issues that lead to diverse user needs impacting web accessibility. For this reason, it may sometimes address a broader scope than web accessibility alone.</p>
<h3> Ensure Human Backup is Available and Reachable </h3>
<p>For users who are unable to use the automated voice system, it must be possible to reach a human through an easy transfer process rather than being directed to call another phone number.</p>
<p>For telephone self-service systems, there should be a reserved digit for requesting a human operator. The most common digit used for this purpose is "0." However, if another digit is already in widespread use in a particular country, then that digit should always be available to get to a human agent.</p>
<p>Systems should avoid making users reach an agent through the use of complex digit combinations. This could be enforced by requiring implementations to</p>
<ul>
    <li>
        use the 0 digit consistently to reach an operator, and  
    </li>
    <li>
        not allow the reserved digit (0) to mean anything other than going to an operator.  
    </li>
</ul>
<p>Other numbers can be used for special actions too, but there shouldn’t be too many—too many rules can be confusing and hard to remember. Also, repeating these options too often can be distracting.</p>
<p>Human help should be trained to support users with disabilities. Too often, human help places users back into the system they did not manage.</p>
<h3> Allow Users To Change Settings </h3>
<p>Make it easy to set user preferences when available, such as adjusting the settings by using natural language ("Slow down!"). Examples of customization include:</p>
<ol>
    <li>
          Extra time should be a user setting for both the speed of speech and for more input time.  
    </li>
    <li>
          Timed text should be adjustable (as with all accessible media).  
    </li>
    <li>
          The user should be able to extend or disable timeout as a system default on their device.  
    </li>
    <li>
          Advertisements and other extraneous information should not be read aloud as they can confuse the user, increase cognitive load, and make it harder to retain attention.  
    </li>
    <li>
          Terms used should be as simple as possible. Uncommon and unfamiliar terms should be explained.  
    </li>
    <li>
          Consider customizable activation phrases for VUIs.  
    </li>
    <li>
          Consider customizable voices, including regional and standard accents, to create familiarity for the user.  
    </li>
</ol>
<h3> Simplify Error Recovery </h3>
<p>Error recovery should be simple and take the user to a human operator. Error response should not end the interaction or lead to a more complex menu. Keypad or telephone-based systems should use a reserved digit to help with error recovery. Example: Setting a default for a human operator as the number 0.</p>
<h3> Design Prompts to Reduce Cognitive Load </h3>
<p>Give prompts in ways that reduce the cognitive load. For example, the prompt "<em>press 1 for the help desk,"</em> requires the user to remember the digit 1 while interpreting the term “help desk.” This wording is harder to process than the prompt "<em>for the help desk (pause): press 1</em>" or "<em>for the help desk (pause) or for more help (pause): press 1.</em>"</p>
<h3> Remove Unnecessary Words </h3>
<p>Avoid additional information such as special offers or extra text that does not support the task directly. For example, the following sentences can cause anxiety or add to the users’ cognitive load:</p>
<ul>
    <li>
          "We are here to help you, and we have been for the last 25 years. We enjoy helping our customers." 
    </li>
    <li>
          "Avoid unnecessary delays by answering the following questions quickly and correctly." 
    </li>
</ul>
<h3> Ensure Voice and Speech Recognition for All Users </h3>
<p>Natural language understanding (NLU) or natural language interpretation (NLI) and AI systems allow users to state their requests in their own words, which can help users who have difficulty remembering menu options or mapping the menu options to their goals. However, the following should be taken into account:</p>
<ol>
    <li>
          Many groups requiring cognitive accessibility supports have different speech patterns. Therefore, the system should be trained and tested with diverse user groups who require cognitive accessibility supports. Train and test speech recognition for users with non-typical speech patterns or speech impairments related to disability. Include contingencies for pauses, use of incorrect terms, and mistakes.  
    </li>
    <li>
          Ensure alternative access for users whose speech is not recognized. Natural language interfaces can be challenging for users who have difficulty producing speech or language. Alternative access should be available. This should include a menu dialog that can work without speech (such as via text), directed dialog (menu-based) fallback, and/or transfer to a human agent.  
    </li>
    <li>
          Make sure fallbacks are tested extensively with a diverse user group to ensure that they do reach human help. Ensure fallbacks do not result in frustrating loops.  
    </li>
    <li>
          Use existing standards for speech recognition if they’re available for the languages your system supports. For example, the European Telecommunications Standards Institute (ETSI) [[ETSI-ES202-076V211]] has a standard for voice commands in many European languages. When using existing standards, keep in mind that asking users to remember too many commands can be overwhelming.  
    </li>
</ol>
<h3> Follow Best Practices in General Voice Interaction Design </h3>
<p>Standard best practices in VUI apply to users with disabilities that impact cognitive accessibility, and should be followed, such as those provided by the Association for Conversational Interaction Design Wiki [[<a   href="http://acixd.org/"> ACIxD </a>]] or <a   href="https://www.etsi.org/deliver/etsi_etr/001_099/096/01_60/etr_096e01p.pdf"> ETSI ETR 096 </a> [[ETSI-ETR-096]].</p>
<p>Some examples of generally accepted best practices in VUI design include:</p>
<ol>
    <li>
          Pauses between phrases to allow processing time.  
    </li>
    <li>
          Long timeouts.  
    </li>
    <li>
          Simple error recovery, taking the user to a human operator if the error persists.  
    </li>
    <li>
          No advertisements or extraneous information.  
    </li>
    <li>
          Jargon-free and simple terms.  
    </li>
    <li>
          Ability to review the conversation as it is happening, such as through a visual log.  
    </li>
</ol>
<p>See the <a   href="http://acixd.org/"> ACIxD wiki </a> [[ACIxD]] for additional recommendations and details.</p>
<h3> Follow Best Practices in Cognitively Accessible VUI Design </h3>
<p>Some specific best practices for users with disabilities that impact cognitive accessibility include:</p>
<ol>
    <li>
          <strong>Manageable lists: </strong>Repeat and/or chunk lists into manageable groups. Each list item should be a single idea.  
    </li>
    <li>
          <strong>Reminders: </strong>Provide cues as to what the user needs to do and when.  
    </li>
    <li>
          <strong>Guided instructions: </strong>Provide instructions to guide the user through the steps in the process.  
    </li>
    <li>
          <strong>Task history:</strong> Include methods that inform the user of what they have done recently to help prevent repeating a task and to inform the user where they are in a process.  
    </li>
    <li>
          <strong>Timers:</strong> Track the user’s time on a step and provide cues or reminders if thresholds of time are crossed.  
    </li>
    <li>
          <strong>Task overview:</strong> Provide a way to attain a list of all the steps required and information needed to complete the task or process.  
    </li>
</ol>
<h3> Follow Appropriate Legislative Requirements </h3>
<p>For example, in Section 255 [[Title42-section255]] of the U.S. Telecommunications Act, paragraph 1193.41 Input, Controls, and Mechanical Functions clauses (g), (h) and (i) apply to cognitive disabilities and require that equipment should be operable without time-dependent controls, the ability to speak, and should be operable by persons with limited cognitive skills.</p>
<h3> Integrate New Technology-Based Solutions </h3>
<p>Recent technological developments may be helpful for users with disabilities that require cognitive accessibility supports.</p>
<ol>
    <li>
          <strong>Visual VUI:</strong> When a call comes in on a smartphone, the system can ask the user if they want to switch to a visual interface that mirrors the voice interface. This allows a user to see the prompts instead of having to remember what they heard. Where possible, supplement text with images, symbols, or icons to increase understandability.  
    </li>
    <li>
          <strong>Adaptive voice interface: </strong>This technology is sensitive to the user's behavior and changes the voice interface dynamically. For example, it can slow down or speed up to match the user's speech rate.  
    </li>
    <li>
          <strong>Tapered prompts: </strong>Best practices in VUI design include adjusting the prompts based on the user's behavior. For example, if the user takes a long time to respond to a prompt, a simpler or more explanatory version of prompts may be used instead of the default.  This approach may give longer instructions with simpler words to users who need more guidance, while allowing experienced users to move quickly through the system. 
          
    </li>
</ol>
<h3> Status of these solutions </h3>
<p>Note: The proposed solutions in this document have been tested for users in the general population and have been shown to improve the usability of voice systems. Some of these solutions have been tested with users with disabilities that require cognitive accessibility supports, primarily in academic research contexts.</p>
<p>Currently, VoiceXML does not directly enforce accessibility for people with disabilities that impact cognitive accessibility. However, considerable literature on VUI design exists and in many cases applies to cognitive accessibility for voice systems. Developers must become aware of these resources and of the need to design systems with these users in mind.</p>


</section></section>
	 <section class="appendix section" id="acknowledgements">
  <h2 id="d-appendix-acknowledgments">Appendix: Acknowledgments</h2>
  
<section >
    <h3 >Key contributors and section editors</h3>
<ul>

	<li>
Deborah Dahl, 
Conversational Technologies

</li>
<li>

Rebecca Monteleone, 
The University of Toledo
		</li><li>
Julie Rawe, 
Understood.org

	</li><li>
Lisa Seeman-Horwitz, 
Invited Expert
</li>

</ul>
</section >


<section >
    <h3 >
Participants active in the Cognitive and Learning Disabilities Task Force at the time of publication
</h3>
<ul>
<li>
Leonard Beasley, 
CVS Pharmacy, Inc.

</li><li>

Rachael Bradley Montgomery, 
Library of Congress

</li><li>

Rain Breaw Michaels, 
Google LLC

</li><li>
Tiffany Burtin, 
Invited Expert 

</li><li>
Deborah Dahl, 
Conversational Technologies

</li><li>
Jennifer Delisi, 
Invited Expert 

</li><li>
E.A. Draffan, 
Global Symbols

</li><li>
Jeanne Erickson Cooley, 
TPGi


</li><li>
Eric Hind, 
Invited Expert 
</li><li>
Rashmi Katakwar, 
Invited Expert 
</li><li>

John Kirkwood, 
CityMouse, inc

</li><li>
Andy Manea, 
Invited Expert 
</li><li>
Jan McSorley, 
Invited Expert 
</li><li>
Rebecca Monteleone, 
The University of Toledo

</li><li>
Abigail Ofer, 
Evinced Inc.

</li><li>

Justine Pascalides, 
Amazon
</li><li>
Ruoxi Ran, 
W3C


</li><li>
Julie Rawe, 
Understood.org


</li><li>
Charlotte Riggle, 
Amazon

</li><li>
John Rochford, 
University of Massachusetts Medical School
</li><li>
Janina Sajka, 
Invited Expert 
</li><li>

Lisa Seeman-Horwitz, 
Invited Expert 
</li><li>

Gareth Slinn, 
Invited Expert 
</li><li>
David Swallow,
TPGi


</li></ul></section>
</section>

</body>
</html>
